{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b69d8f0a-c89e-401d-bd04-5d63e95f2c61",
   "metadata": {},
   "source": [
    "# L6. Numerical Optimization\n",
    "\n",
    "> \"Economics is the science of optimizing agents,\" Nikhil Agarwal (2022)\n",
    "\n",
    "Optimization is ubiquitous in Economics:\n",
    "- Structural Models: firms maximize profits or minimize cost, consumers maximize utility, the Social Planner maximizes welfare, etc.\n",
    "- Econometrics: most estimators we use are extremum estimators that arise from minimizing a loss function (OLS, GMM, ML methods) or maximizing a log-likelihood (MLE)\n",
    "- Dynamic Programming: the RHS of the Bellman equation is an optimization problem\n",
    "- Game Theory: agents best-respond to each other, i.e., they maximize their payoffs given others' actions\n",
    "\n",
    "In this lecture we will learn about how numerical optimization methods work so that we know their pros and cons and when to apply them.\n",
    "\n",
    "All these methods are already implemented efficiently in Julia. If something is already implemented, it is generally a good idea to *not* code your algorithm from scratch, but use the existing implementation. Moreover, this lecture will focus on the basics of how the methods work, but most modern implementations combine these basic principles with clever fine-tunings of various parameters to maximize performance.\n",
    "\n",
    "## 1. Unconstrained Optimization with ```Optim.jl```\n",
    "Suppose that we are trying to solve the following problem:\n",
    "$$\\min_{x \\in \\mathbb{R}^n} f(x).$$\n",
    "\n",
    "### 1.1. Gradient-Free Methods\n",
    "Gradient-free methods are direct-search methods, which try to find an optimum without using gradient information.\n",
    "\n",
    "1. **Nelder-Mead**: The algorithm works as follows. At each step, we start with a set of $n+1$ test points $x_1, \\ldots, x_{n+1}$.\n",
    "    1. If the standard deviation of the function values at those test points is less than a pre-specified tolerance, _stop_. Otherwise, proceed.\n",
    "    2. _Order_ the test points according to the values at the vertices, so that $$f(x_1) \\leq f(x_2) \\leq \\cdots \\leq f(x_{n+1}).$$\n",
    "    3. Calculate $x_0$, the _centroid_ of all points except $x_{n+1}$.\n",
    "    4. _Reflection_: Compute the reflected point $x_r = x_0 + \\alpha(x_0 - x_{n+1})$ for some pre-specified $\\alpha > 0$. If $f(x_1) \\leq f(x_r) < f(x_n)$, i.e. the reflected point is better than the second-worst but not better than the best, then replace the worst point $x_{n+1}$ with the reflected point $x_r$ and go back to Step A. Else, continue to _Expansion_ if $f(x_r) < f(x_1)$, or _Contraction_ if $f(x_r) \\geq f(x_n)$.\n",
    "    5. _Expansion_: If $f(x_r) < f(x_1)$, i.e. reflected point is the best point so far, then compute the expanded point $x_e = x_0 + \\gamma (x_r - x_0)$ for some pre-specified $\\gamma > 1$. If $f(x_e) < f(x_r)$ then replace $x_{n+1}$ with $x_e$ and go back to Step A. Else, replace $x_{n+1}$ with $x_r$ and go back to Step A.\n",
    "    6. _Contraction_: If $f(x_r) \\geq f(x_{n})$, i.e. the reflected point is no better than the second-worse, then:\n",
    "        1. If $f(x_r) < f(x_{n+1})$, then compute the contracted point on the outside, $x_c = x_0 + \\rho(x_r - x_0)$ for a pre-specified $0<\\rho\\leq 0.5$. If $f(x_c) < f(x_r)$, then replace $x_{n+1}$ with $x_c$ and go back to Step A. Else, proceed to _Shrink_.\n",
    "        2. If $f(x_r) \\geq f(x_{n+1})$, then compute the contracted point on the inside, $x_c = x_0 + \\rho(x_{n+1} - x_0)$. If $f(x_c) < f(x_r)$, then replace $x_{n+1}$ with $x_c$ and go back to Step A. Else, proceed to _Shrink_.\n",
    "     7. _Shrink_: Replace all points except the best $x_1$ with $x_i = x_1 + \\sigma (x_i - x_1)$ for some $0 < \\sigma \\leq 1$, and go back to Step A.\n",
    "   \n",
    "Standard values for the parameters are $\\alpha = 1$, $\\gamma = 2$ and $\\rho=\\sigma = 1/2$.\n",
    "\n",
    "(Note: the figure below is for maximization, replace $p_{\\max}$ with $x_1$ and $p_{\\min}$ with $x_{n+1}$, in this case $x_3$.)\n",
    "\n",
    "![Nelder-Mead options in a step](https://upload.wikimedia.org/wikipedia/commons/7/72/An-iteration-of-the-Nelder-Mead-method-over-two-dimensional-space-showing-point-p-min.png \"Nelder-Mead step\")\n",
    "\n",
    "![Nelder-Mead Search for Rosenbrock Function](https://upload.wikimedia.org/wikipedia/commons/e/e4/Nelder-Mead_Rosenbrock.gif \"Nelder-Mead Rosenbrock\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a85ec0f4-7aa3-4705-b1a6-64528c5824a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " * Status: success\n",
       "\n",
       " * Candidate solution\n",
       "    Final objective value:     3.525527e-09\n",
       "\n",
       " * Found with\n",
       "    Algorithm:     Nelder-Mead\n",
       "\n",
       " * Convergence measures\n",
       "    √(Σ(yᵢ-ȳ)²)/n ≤ 1.0e-08\n",
       "\n",
       " * Work counters\n",
       "    Seconds run:   0  (vs limit Inf)\n",
       "    Iterations:    60\n",
       "    f(x) calls:    117\n"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using Optim\n",
    "\n",
    "# Rosenbrock Function: usual benchmark in numerical optimization\n",
    "f(x) = (1.0 - x[1])^2 + 100.0*(x[2] - x[1]^2)^2;\n",
    "\n",
    "# By default, Optim does minimization. Use maximize to do maximization.\n",
    "# Nelder-Mead is the default algorithm\n",
    "result = optimize(f, [0.0, 0.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c47676c8-c56f-48e1-8dc1-6984e281c734",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optim.converged(result) = true\n",
      "result.minimum = 3.5255270584829996e-9\n",
      "result.minimizer = [0.9999634355313174, 0.9999315506115275]\n"
     ]
    }
   ],
   "source": [
    "@show Optim.converged(result)\n",
    "@show result.minimum\n",
    "@show result.minimizer;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5ef90eb-3439-4997-a541-c3c68a473751",
   "metadata": {},
   "source": [
    "### 1.2. Gradient-Required and Hessian-Required Methods\n",
    "These methods are based on the idea that, if the function is twice differentiable at the minimizer $x^*$, then the gradient $\\nabla f(x^*) = 0$ and the Hessian $H(x^*)$ will be positive (semi-)definite.\n",
    "\n",
    "1. **Newton Method**: This is based on a linear Taylor approximation of the above:\n",
    "$$\\nabla f(x^*) \\approx \\nabla f(x) + H(x)(x^* - x),$$ which suggests using the following iterative algorithm: $$x_{t+1} = x_t - H(x_t)^{-1}\\nabla f(x_t).$$\n",
    "2. **Quasi-Newton Methods**: When the Hessian is difficult or computationally expensive to obtain, we might replace it with another positive definite matrix that approximates it:\n",
    "$$x_{t+1} = x_t - \\alpha P^{-1}\\nabla f(x_t).$$ \n",
    "\n",
    "    One example is **Gradient Descent**, where $P$ is a diagonal matrix. This procedure does not use information about the curvature of the function, and so it can be slow if the problem is ill-conditioned (a small change in $x$ changes $f(x)$ by a lot). In ```Optim.jl```, the scalar $\\alpha$ is chosen by linesearch so that each step gives sufficient descent.\n",
    "    \n",
    "    Another example is **(L-)BFGS**, which takes as $P$ an approximation to the Hessian using differences in the gradient across iterations. The L-BFGS version of BFGS is a \"limited memory\" version, that only uses the latest $m$ gradients to approximate the Hessian.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "72597593-46cf-4261-ad0b-35bd21a3f0fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " * Status: success\n",
       "\n",
       " * Candidate solution\n",
       "    Final objective value:     5.378405e-17\n",
       "\n",
       " * Found with\n",
       "    Algorithm:     L-BFGS\n",
       "\n",
       " * Convergence measures\n",
       "    |x - x'|               = 4.54e-11 ≰ 0.0e+00\n",
       "    |x - x'|/|x'|          = 4.54e-11 ≰ 0.0e+00\n",
       "    |f(x) - f(x')|         = 2.85e-19 ≰ 0.0e+00\n",
       "    |f(x) - f(x')|/|f(x')| = 5.29e-03 ≰ 0.0e+00\n",
       "    |g(x)|                 = 1.21e-13 ≤ 1.0e-08\n",
       "\n",
       " * Work counters\n",
       "    Seconds run:   0  (vs limit Inf)\n",
       "    Iterations:    24\n",
       "    f(x) calls:    67\n",
       "    ∇f(x) calls:   67\n"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = optimize(f, [0.0, 0.0], LBFGS())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "403370df-63d8-4afb-8d93-fd7753894e55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optim.converged(result) = true\n",
      "result.minimum = 5.3784046148998115e-17\n",
      "result.minimizer = [0.9999999926662393, 0.9999999853324786]\n"
     ]
    }
   ],
   "source": [
    "@show Optim.converged(result) \n",
    "@show result.minimum\n",
    "@show result.minimizer;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c71f692f-d1a8-41dc-a91f-a4839a6f35cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.000079 seconds (296 allocations: 7.016 KiB)\n",
      "  0.000158 seconds (531 allocations: 23.344 KiB)\n",
      "  0.000068 seconds (597 allocations: 25.516 KiB)\n",
      "  0.003555 seconds (3.87 k allocations: 228.859 KiB, 98.35% compilation time: 100% of which was recompilation)\n",
      "  0.000048 seconds (356 allocations: 18.000 KiB)\n",
      "  0.000086 seconds (390 allocations: 20.125 KiB)\n",
      "  0.003332 seconds (2.41 k allocations: 145.344 KiB, 98.55% compilation time)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       " * Status: success\n",
       "\n",
       " * Candidate solution\n",
       "    Final objective value:     3.081488e-31\n",
       "\n",
       " * Found with\n",
       "    Algorithm:     Newton's Method\n",
       "\n",
       " * Convergence measures\n",
       "    |x - x'|               = 3.06e-09 ≰ 0.0e+00\n",
       "    |x - x'|/|x'|          = 3.06e-09 ≰ 0.0e+00\n",
       "    |f(x) - f(x')|         = 9.34e-18 ≰ 0.0e+00\n",
       "    |f(x) - f(x')|/|f(x')| = 3.03e+13 ≰ 0.0e+00\n",
       "    |g(x)|                 = 1.11e-15 ≤ 1.0e-08\n",
       "\n",
       " * Work counters\n",
       "    Seconds run:   0  (vs limit Inf)\n",
       "    Iterations:    14\n",
       "    f(x) calls:    44\n",
       "    ∇f(x) calls:   44\n",
       "    ∇²f(x) calls:  14\n"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# By default, LBFGS will use finite differences to approximate the gradient of f(x).\n",
    "# You can also supply the gradient of f directly, either by deriving it analytically\n",
    "# or with AD:\n",
    "\n",
    "function g!(G, x)\n",
    "    G[1] = -2.0 * (1.0 - x[1]) - 400.0 * (x[2] - x[1]^2) * x[1]\n",
    "    G[2] = 200.0 * (x[2] - x[1]^2)\n",
    "end\n",
    "\n",
    "function h!(H, x)\n",
    "    H[1, 1] = 2.0 - 400.0 * x[2] + 1200.0 * x[1]^2\n",
    "    H[1, 2] = -400.0 * x[1]\n",
    "    H[2, 1] = -400.0 * x[1]\n",
    "    H[2, 2] = 200.0\n",
    "end\n",
    "\n",
    "@time optimize(f, [0.0, 0.0], NelderMead())\n",
    "@time optimize(f, [0.0, 0.0], LBFGS())\n",
    "@time optimize(f, [0.0, 0.0], LBFGS(), autodiff=:forward) # i.e. use ForwardDiff.jl\n",
    "@time optimize(f, g!, [0.0, 0.0], LBFGS())\n",
    "@time optimize(f, [0.0, 0.0], Newton())\n",
    "@time optimize(f, [0.0, 0.0], Newton(), autodiff=:forward) # i.e. use ForwardDiff.jl\n",
    "@time optimize(f, g!, h!, [0.0, 0.0], Newton())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c714bd3f-e22e-4564-96dc-17166c0e6214",
   "metadata": {},
   "source": [
    "## 2. Constrained Optimization with ```Optim.jl```\n",
    "Recently, a Julia package previously known as ```ConstrainedOptim.jl``` was merged into ```Optim.jl```. This package supports optimization of the form:\n",
    "\\begin{align*}\n",
    "\\min_{x \\in \\mathbb{R}^n} \\quad & f(x) \\\\\n",
    "\\text{subj. to} \\quad & l_x \\leq x \\leq u_x \\\\\n",
    "& l_c \\leq c(x) \\leq u_c,\n",
    "\\end{align*}\n",
    "where $c(x)$ is a vector of constraints. Notice that this includes also equality constraints $c(x) = C$ by defining $l_c = u_c = C$.\n",
    "\n",
    "```Optim.jl``` currently has one algorithm for this type of problems, Interior Point Newton ```IPNewton()```, which applies Newton's method to the KKT conditions.\n",
    "\n",
    "To see how it works, let us re-write the problem as:\n",
    "\\begin{align*}\n",
    "\\min_{x \\in \\mathbb{R}^n, s} \\quad & f(x) \\\\\n",
    "\\text{subj. to} \\quad & A(x) - s = 0 \\\\\n",
    "& s \\geq 0,\n",
    "\\end{align*} \n",
    "\n",
    "where we have summarized all constraints in $A(x) \\geq 0$, so $A(x) = [(x - l_x)', (u_x - x)', (c(x) - l_c)', (u_c - c(x))']'$, and we have introduced the slack variables $s$.\n",
    "\n",
    "Then, the KKT conditions are: \n",
    "\\begin{align*}\n",
    "\\nabla f(x) - \\nabla A(x)'\\lambda = 0 \\\\\n",
    "\\mathrm{diag}(s) \\lambda = 0 \\\\\n",
    "A(x) - s = 0 \\\\\n",
    "s \\geq 0, \\lambda \\geq 0\n",
    "\\end{align*}\n",
    "\n",
    "where $\\mathrm{diag}(s)$ is a diagonal matrix with $s$ as its diagonal and $\\lambda$ is the vector of Lagrange multipliers. \n",
    "\n",
    "Instead of imposing complementary slackness strictly, the method considers $\\mathrm{diag}(s) \\lambda = \\mu_k \\mathbf{1}$ for a sequence of $\\mu_k \\to 0$ as the steps of the maximization proceed. The Newton steps corresponding to the above conditions are: \\begin{align*}\n",
    "\\begin{bmatrix}\n",
    "p_x \\\\\n",
    "p_s \\\\\n",
    "p_\\lambda \n",
    "\\end{bmatrix} =\n",
    "\\begin{bmatrix}\n",
    "\\nabla^2 f(x) - \\nabla^2 A(x)' & 0 &  - \\nabla A(x)'\\\\\n",
    "0 & \\mathrm{diag}(\\lambda) & \\mathrm{diag}(s) \\\\\n",
    "\\nabla A(x) & -I & 0\n",
    "\\end{bmatrix}^{-1} \\begin{bmatrix}\n",
    "\\nabla f(x) - \\nabla A(x)'\\lambda \\\\\n",
    "\\mathrm{diag}(s) \\lambda - \\mu_k \\mathbf{1}\\\\\n",
    "A(x) - s\n",
    "\\end{bmatrix}\n",
    "\\end{align*}\n",
    "\n",
    "and the updates at each step are $x^{k+1} = x^k + \\alpha p_x$ where $\\alpha \\in (0, 1]$ is chosen small enough so that $x$ does not hit the boundary of the feasible region (and likewise for $s$ and $\\lambda$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "855ce047-f6b7-48d0-b2c3-2b0f1228a36f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " * Status: success\n",
       "\n",
       " * Candidate solution\n",
       "    Final objective value:     2.966216e-01\n",
       "\n",
       " * Found with\n",
       "    Algorithm:     Interior Point Newton\n",
       "\n",
       " * Convergence measures\n",
       "    |x - x'|               = 0.00e+00 ≤ 0.0e+00\n",
       "    |x - x'|/|x'|          = 0.00e+00 ≤ 0.0e+00\n",
       "    |f(x) - f(x')|         = 0.00e+00 ≤ 0.0e+00\n",
       "    |f(x) - f(x')|/|f(x')| = 0.00e+00 ≤ 0.0e+00\n",
       "    |g(x)|                 = 7.71e-01 ≰ 1.0e-08\n",
       "\n",
       " * Work counters\n",
       "    Seconds run:   0  (vs limit Inf)\n",
       "    Iterations:    43\n",
       "    f(x) calls:    100\n",
       "    ∇f(x) calls:   100\n"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "con_c!(c, x) = (c[1] = x[1]^2 + x[2]^2; c)\n",
    "lx = [-Inf, -Inf]; ux = [Inf, Inf]\n",
    "lc = [-Inf]; uc = [0.5^2]\n",
    "dfc = TwiceDifferentiableConstraints(con_c!, lx, ux, lc, uc)\n",
    "res = optimize(f, dfc, [0.0, 0.0], IPNewton())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "de0c7145-45a7-4857-913e-75b7d4c854bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2-element Vector{Float64}:\n",
       " 0.45564896411795214\n",
       " 0.20587379993150445"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.minimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf09a098-532e-47c0-9deb-acbaa45358d2",
   "metadata": {},
   "source": [
    "## 3. Global Optimization with ```BlackBoxOptim.jl```\n",
    "\n",
    "A drawback of all the methods we've seen above is that, if the function is not globally strictly convex (concave), the optimizer may converge to a local minimum (maximum). For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6bb8005b-9544-429f-a2c9-63d3c4134e8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"utf-8\"?>\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"600\" height=\"400\" viewBox=\"0 0 2400 1600\">\n",
       "<defs>\n",
       "  <clipPath id=\"clip450\">\n",
       "    <rect x=\"0\" y=\"0\" width=\"2400\" height=\"1600\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<path clip-path=\"url(#clip450)\" d=\"M0 1600 L2400 1600 L2400 0 L0 0  Z\" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<defs>\n",
       "  <clipPath id=\"clip451\">\n",
       "    <rect x=\"480\" y=\"0\" width=\"1681\" height=\"1600\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<path clip-path=\"url(#clip450)\" d=\"M149.191 1486.45 L2352.76 1486.45 L2352.76 47.2441 L149.191 47.2441  Z\" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<defs>\n",
       "  <clipPath id=\"clip452\">\n",
       "    <rect x=\"149\" y=\"47\" width=\"2205\" height=\"1440\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<polyline clip-path=\"url(#clip452)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"211.556,1486.45 211.556,47.2441 \"/>\n",
       "<polyline clip-path=\"url(#clip452)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"673.519,1486.45 673.519,47.2441 \"/>\n",
       "<polyline clip-path=\"url(#clip452)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"1135.48,1486.45 1135.48,47.2441 \"/>\n",
       "<polyline clip-path=\"url(#clip452)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"1597.45,1486.45 1597.45,47.2441 \"/>\n",
       "<polyline clip-path=\"url(#clip452)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"2059.41,1486.45 2059.41,47.2441 \"/>\n",
       "<polyline clip-path=\"url(#clip450)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"149.191,1486.45 2352.76,1486.45 \"/>\n",
       "<polyline clip-path=\"url(#clip450)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"211.556,1486.45 211.556,1467.55 \"/>\n",
       "<polyline clip-path=\"url(#clip450)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"673.519,1486.45 673.519,1467.55 \"/>\n",
       "<polyline clip-path=\"url(#clip450)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"1135.48,1486.45 1135.48,1467.55 \"/>\n",
       "<polyline clip-path=\"url(#clip450)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"1597.45,1486.45 1597.45,1467.55 \"/>\n",
       "<polyline clip-path=\"url(#clip450)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"2059.41,1486.45 2059.41,1467.55 \"/>\n",
       "<path clip-path=\"url(#clip450)\" d=\"M180.457 1532.02 L210.132 1532.02 L210.132 1535.95 L180.457 1535.95 L180.457 1532.02 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip450)\" d=\"M233.072 1518.36 L221.267 1536.81 L233.072 1536.81 L233.072 1518.36 M231.845 1514.29 L237.725 1514.29 L237.725 1536.81 L242.655 1536.81 L242.655 1540.7 L237.725 1540.7 L237.725 1548.85 L233.072 1548.85 L233.072 1540.7 L217.47 1540.7 L217.47 1536.19 L231.845 1514.29 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip450)\" d=\"M643.462 1532.02 L673.137 1532.02 L673.137 1535.95 L643.462 1535.95 L643.462 1532.02 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip450)\" d=\"M687.258 1544.91 L703.577 1544.91 L703.577 1548.85 L681.633 1548.85 L681.633 1544.91 Q684.295 1542.16 688.878 1537.53 Q693.484 1532.88 694.665 1531.53 Q696.91 1529.01 697.79 1527.27 Q698.693 1525.51 698.693 1523.82 Q698.693 1521.07 696.748 1519.33 Q694.827 1517.6 691.725 1517.6 Q689.526 1517.6 687.072 1518.36 Q684.642 1519.13 681.864 1520.68 L681.864 1515.95 Q684.688 1514.82 687.142 1514.24 Q689.596 1513.66 691.633 1513.66 Q697.003 1513.66 700.197 1516.35 Q703.392 1519.03 703.392 1523.52 Q703.392 1525.65 702.582 1527.57 Q701.795 1529.47 699.688 1532.07 Q699.109 1532.74 696.008 1535.95 Q692.906 1539.15 687.258 1544.91 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip450)\" d=\"M1135.48 1517.37 Q1131.87 1517.37 1130.04 1520.93 Q1128.24 1524.47 1128.24 1531.6 Q1128.24 1538.71 1130.04 1542.27 Q1131.87 1545.82 1135.48 1545.82 Q1139.12 1545.82 1140.92 1542.27 Q1142.75 1538.71 1142.75 1531.6 Q1142.75 1524.47 1140.92 1520.93 Q1139.12 1517.37 1135.48 1517.37 M1135.48 1513.66 Q1141.29 1513.66 1144.35 1518.27 Q1147.43 1522.85 1147.43 1531.6 Q1147.43 1540.33 1144.35 1544.94 Q1141.29 1549.52 1135.48 1549.52 Q1129.67 1549.52 1126.59 1544.94 Q1123.54 1540.33 1123.54 1531.6 Q1123.54 1522.85 1126.59 1518.27 Q1129.67 1513.66 1135.48 1513.66 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip450)\" d=\"M1592.1 1544.91 L1608.42 1544.91 L1608.42 1548.85 L1586.47 1548.85 L1586.47 1544.91 Q1589.14 1542.16 1593.72 1537.53 Q1598.33 1532.88 1599.51 1531.53 Q1601.75 1529.01 1602.63 1527.27 Q1603.53 1525.51 1603.53 1523.82 Q1603.53 1521.07 1601.59 1519.33 Q1599.67 1517.6 1596.57 1517.6 Q1594.37 1517.6 1591.91 1518.36 Q1589.48 1519.13 1586.71 1520.68 L1586.71 1515.95 Q1589.53 1514.82 1591.98 1514.24 Q1594.44 1513.66 1596.47 1513.66 Q1601.84 1513.66 1605.04 1516.35 Q1608.23 1519.03 1608.23 1523.52 Q1608.23 1525.65 1607.42 1527.57 Q1606.64 1529.47 1604.53 1532.07 Q1603.95 1532.74 1600.85 1535.95 Q1597.75 1539.15 1592.1 1544.91 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip450)\" d=\"M2062.42 1518.36 L2050.61 1536.81 L2062.42 1536.81 L2062.42 1518.36 M2061.19 1514.29 L2067.07 1514.29 L2067.07 1536.81 L2072 1536.81 L2072 1540.7 L2067.07 1540.7 L2067.07 1548.85 L2062.42 1548.85 L2062.42 1540.7 L2046.82 1540.7 L2046.82 1536.19 L2061.19 1514.29 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><polyline clip-path=\"url(#clip452)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"149.191,1479.62 2352.76,1479.62 \"/>\n",
       "<polyline clip-path=\"url(#clip452)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"149.191,1273.27 2352.76,1273.27 \"/>\n",
       "<polyline clip-path=\"url(#clip452)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"149.191,1066.93 2352.76,1066.93 \"/>\n",
       "<polyline clip-path=\"url(#clip452)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"149.191,860.58 2352.76,860.58 \"/>\n",
       "<polyline clip-path=\"url(#clip452)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"149.191,654.234 2352.76,654.234 \"/>\n",
       "<polyline clip-path=\"url(#clip452)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"149.191,447.887 2352.76,447.887 \"/>\n",
       "<polyline clip-path=\"url(#clip452)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"149.191,241.541 2352.76,241.541 \"/>\n",
       "<polyline clip-path=\"url(#clip450)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"149.191,1486.45 149.191,47.2441 \"/>\n",
       "<polyline clip-path=\"url(#clip450)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"149.191,1479.62 168.089,1479.62 \"/>\n",
       "<polyline clip-path=\"url(#clip450)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"149.191,1273.27 168.089,1273.27 \"/>\n",
       "<polyline clip-path=\"url(#clip450)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"149.191,1066.93 168.089,1066.93 \"/>\n",
       "<polyline clip-path=\"url(#clip450)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"149.191,860.58 168.089,860.58 \"/>\n",
       "<polyline clip-path=\"url(#clip450)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"149.191,654.234 168.089,654.234 \"/>\n",
       "<polyline clip-path=\"url(#clip450)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"149.191,447.887 168.089,447.887 \"/>\n",
       "<polyline clip-path=\"url(#clip450)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"149.191,241.541 168.089,241.541 \"/>\n",
       "<path clip-path=\"url(#clip450)\" d=\"M50.9921 1480.07 L80.6679 1480.07 L80.6679 1484.01 L50.9921 1484.01 L50.9921 1480.07 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip450)\" d=\"M103.608 1466.41 L91.8021 1484.86 L103.608 1484.86 L103.608 1466.41 M102.381 1462.34 L108.26 1462.34 L108.26 1484.86 L113.191 1484.86 L113.191 1488.75 L108.26 1488.75 L108.26 1496.9 L103.608 1496.9 L103.608 1488.75 L88.0058 1488.75 L88.0058 1484.24 L102.381 1462.34 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip450)\" d=\"M52.1264 1273.72 L81.8021 1273.72 L81.8021 1277.66 L52.1264 1277.66 L52.1264 1273.72 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip450)\" d=\"M106.061 1271.92 Q109.418 1272.64 111.293 1274.9 Q113.191 1277.17 113.191 1280.51 Q113.191 1285.62 109.672 1288.42 Q106.154 1291.22 99.6724 1291.22 Q97.4965 1291.22 95.1817 1290.78 Q92.89 1290.37 90.4364 1289.51 L90.4364 1285 Q92.3808 1286.13 94.6956 1286.71 Q97.0104 1287.29 99.5335 1287.29 Q103.932 1287.29 106.223 1285.55 Q108.538 1283.82 108.538 1280.51 Q108.538 1277.45 106.385 1275.74 Q104.256 1274 100.436 1274 L96.4085 1274 L96.4085 1270.16 L100.621 1270.16 Q104.071 1270.16 105.899 1268.79 Q107.728 1267.4 107.728 1264.81 Q107.728 1262.15 105.83 1260.74 Q103.955 1259.3 100.436 1259.3 Q98.515 1259.3 96.316 1259.72 Q94.1169 1260.14 91.478 1261.02 L91.478 1256.85 Q94.14 1256.11 96.4548 1255.74 Q98.7928 1255.37 100.853 1255.37 Q106.177 1255.37 109.279 1257.8 Q112.381 1260.21 112.381 1264.33 Q112.381 1267.2 110.737 1269.19 Q109.094 1271.15 106.061 1271.92 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip450)\" d=\"M53.0754 1067.38 L82.7512 1067.38 L82.7512 1071.31 L53.0754 1071.31 L53.0754 1067.38 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip450)\" d=\"M96.8715 1080.27 L113.191 1080.27 L113.191 1084.21 L91.2465 1084.21 L91.2465 1080.27 Q93.9086 1077.52 98.4919 1072.89 Q103.098 1068.23 104.279 1066.89 Q106.524 1064.37 107.404 1062.63 Q108.307 1060.87 108.307 1059.18 Q108.307 1056.43 106.362 1054.69 Q104.441 1052.96 101.339 1052.96 Q99.14 1052.96 96.6863 1053.72 Q94.2558 1054.48 91.478 1056.04 L91.478 1051.31 Q94.3021 1050.18 96.7558 1049.6 Q99.2095 1049.02 101.246 1049.02 Q106.617 1049.02 109.811 1051.71 Q113.006 1054.39 113.006 1058.88 Q113.006 1061.01 112.196 1062.93 Q111.408 1064.83 109.302 1067.42 Q108.723 1068.1 105.621 1071.31 Q102.52 1074.51 96.8715 1080.27 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip450)\" d=\"M52.7051 861.031 L82.3808 861.031 L82.3808 864.967 L52.7051 864.967 L52.7051 861.031 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip450)\" d=\"M93.2836 873.925 L100.922 873.925 L100.922 847.559 L92.6123 849.226 L92.6123 844.967 L100.876 843.3 L105.552 843.3 L105.552 873.925 L113.191 873.925 L113.191 877.86 L93.2836 877.86 L93.2836 873.925 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip450)\" d=\"M101.246 640.032 Q97.6354 640.032 95.8067 643.597 Q94.0012 647.139 94.0012 654.268 Q94.0012 661.375 95.8067 664.94 Q97.6354 668.481 101.246 668.481 Q104.881 668.481 106.686 664.94 Q108.515 661.375 108.515 654.268 Q108.515 647.139 106.686 643.597 Q104.881 640.032 101.246 640.032 M101.246 636.329 Q107.057 636.329 110.112 640.935 Q113.191 645.519 113.191 654.268 Q113.191 662.995 110.112 667.602 Q107.057 672.185 101.246 672.185 Q95.4363 672.185 92.3576 667.602 Q89.3021 662.995 89.3021 654.268 Q89.3021 645.519 92.3576 640.935 Q95.4363 636.329 101.246 636.329 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip450)\" d=\"M93.2836 461.232 L100.922 461.232 L100.922 434.867 L92.6123 436.533 L92.6123 432.274 L100.876 430.607 L105.552 430.607 L105.552 461.232 L113.191 461.232 L113.191 465.167 L93.2836 465.167 L93.2836 461.232 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip450)\" d=\"M96.8715 254.886 L113.191 254.886 L113.191 258.821 L91.2465 258.821 L91.2465 254.886 Q93.9086 252.131 98.4919 247.502 Q103.098 242.849 104.279 241.506 Q106.524 238.983 107.404 237.247 Q108.307 235.488 108.307 233.798 Q108.307 231.044 106.362 229.307 Q104.441 227.571 101.339 227.571 Q99.14 227.571 96.6863 228.335 Q94.2558 229.099 91.478 230.65 L91.478 225.928 Q94.3021 224.794 96.7558 224.215 Q99.2095 223.636 101.246 223.636 Q106.617 223.636 109.811 226.321 Q113.006 229.007 113.006 233.497 Q113.006 235.627 112.196 237.548 Q111.408 239.446 109.302 242.039 Q108.723 242.71 105.621 245.928 Q102.52 249.122 96.8715 254.886 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><polyline clip-path=\"url(#clip452)\" style=\"stroke:#009af9; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"211.556,537.755 232.554,468.377 253.553,403.848 274.551,344.616 295.549,291.058 316.548,243.481 337.546,202.115 358.544,167.115 379.543,138.565 400.541,116.473 421.539,100.776 442.538,91.3433 463.536,87.9763 484.534,90.4162 505.533,98.3467 526.531,111.399 547.529,129.157 568.528,151.166 589.526,176.934 610.524,205.944 631.523,237.656 652.521,271.516 673.519,306.965 694.518,343.441 715.516,380.392 736.514,417.276 757.513,453.572 778.511,488.787 799.509,522.456 820.508,554.153 841.506,583.494 862.504,610.139 883.503,633.798 904.501,654.234 925.499,671.264 946.498,684.761 967.496,694.656 988.494,700.938 1009.49,703.65 1030.49,702.895 1051.49,698.825 1072.49,691.648 1093.49,681.618 1114.48,669.033 1135.48,654.234 1156.48,637.594 1177.48,619.519 1198.48,600.439 1219.48,580.803 1240.47,561.073 1261.47,541.717 1282.47,523.205 1303.47,505.997 1324.47,490.545 1345.47,477.278 1366.46,466.604 1387.46,458.896 1408.46,454.494 1429.46,453.696 1450.46,456.753 1471.46,463.868 1492.45,475.188 1513.45,490.805 1534.45,510.752 1555.45,535.002 1576.45,563.466 1597.45,595.995 1618.44,632.376 1639.44,672.339 1660.44,715.556 1681.44,761.643 1702.44,810.165 1723.44,860.641 1744.43,912.543 1765.43,965.31 1786.43,1018.35 1807.43,1071.03 1828.43,1122.72 1849.43,1172.77 1870.42,1220.53 1891.42,1265.32 1912.42,1306.52 1933.42,1343.5 1954.42,1375.66 1975.42,1402.42 1996.41,1423.26 2017.41,1437.7 2038.41,1445.31 2059.41,1445.72 2080.41,1438.62 2101.41,1423.79 2122.4,1401.07 2143.4,1370.36 2164.4,1331.68 2185.4,1285.1 2206.4,1230.79 2227.4,1169 2248.39,1100.07 2269.39,1024.4 2290.39,942.516 \"/>\n",
       "<path clip-path=\"url(#clip450)\" d=\"M2006.52 198.898 L2279.3 198.898 L2279.3 95.2176 L2006.52 95.2176  Z\" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<polyline clip-path=\"url(#clip450)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"2006.52,198.898 2279.3,198.898 2279.3,95.2176 2006.52,95.2176 2006.52,198.898 \"/>\n",
       "<polyline clip-path=\"url(#clip450)\" style=\"stroke:#009af9; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"2031,147.058 2177.91,147.058 \"/>\n",
       "<path clip-path=\"url(#clip450)\" d=\"M2216.23 166.745 Q2214.43 171.375 2212.71 172.787 Q2211 174.199 2208.13 174.199 L2204.73 174.199 L2204.73 170.634 L2207.23 170.634 Q2208.99 170.634 2209.96 169.8 Q2210.93 168.967 2212.11 165.865 L2212.88 163.921 L2202.39 138.412 L2206.9 138.412 L2215.01 158.689 L2223.11 138.412 L2227.62 138.412 L2216.23 166.745 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip450)\" d=\"M2234.91 160.402 L2242.55 160.402 L2242.55 134.037 L2234.24 135.703 L2234.24 131.444 L2242.5 129.778 L2247.18 129.778 L2247.18 160.402 L2254.82 160.402 L2254.82 164.338 L2234.91 164.338 L2234.91 160.402 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /></svg>\n"
      ],
      "text/html": [
       "<?xml version=\"1.0\" encoding=\"utf-8\"?>\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"600\" height=\"400\" viewBox=\"0 0 2400 1600\">\n",
       "<defs>\n",
       "  <clipPath id=\"clip500\">\n",
       "    <rect x=\"0\" y=\"0\" width=\"2400\" height=\"1600\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<path clip-path=\"url(#clip500)\" d=\"M0 1600 L2400 1600 L2400 0 L0 0  Z\" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<defs>\n",
       "  <clipPath id=\"clip501\">\n",
       "    <rect x=\"480\" y=\"0\" width=\"1681\" height=\"1600\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<path clip-path=\"url(#clip500)\" d=\"M149.191 1486.45 L2352.76 1486.45 L2352.76 47.2441 L149.191 47.2441  Z\" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<defs>\n",
       "  <clipPath id=\"clip502\">\n",
       "    <rect x=\"149\" y=\"47\" width=\"2205\" height=\"1440\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<polyline clip-path=\"url(#clip502)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"211.556,1486.45 211.556,47.2441 \"/>\n",
       "<polyline clip-path=\"url(#clip502)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"673.519,1486.45 673.519,47.2441 \"/>\n",
       "<polyline clip-path=\"url(#clip502)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"1135.48,1486.45 1135.48,47.2441 \"/>\n",
       "<polyline clip-path=\"url(#clip502)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"1597.45,1486.45 1597.45,47.2441 \"/>\n",
       "<polyline clip-path=\"url(#clip502)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"2059.41,1486.45 2059.41,47.2441 \"/>\n",
       "<polyline clip-path=\"url(#clip500)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"149.191,1486.45 2352.76,1486.45 \"/>\n",
       "<polyline clip-path=\"url(#clip500)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"211.556,1486.45 211.556,1467.55 \"/>\n",
       "<polyline clip-path=\"url(#clip500)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"673.519,1486.45 673.519,1467.55 \"/>\n",
       "<polyline clip-path=\"url(#clip500)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"1135.48,1486.45 1135.48,1467.55 \"/>\n",
       "<polyline clip-path=\"url(#clip500)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"1597.45,1486.45 1597.45,1467.55 \"/>\n",
       "<polyline clip-path=\"url(#clip500)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"2059.41,1486.45 2059.41,1467.55 \"/>\n",
       "<path clip-path=\"url(#clip500)\" d=\"M180.457 1532.02 L210.132 1532.02 L210.132 1535.95 L180.457 1535.95 L180.457 1532.02 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip500)\" d=\"M233.072 1518.36 L221.267 1536.81 L233.072 1536.81 L233.072 1518.36 M231.845 1514.29 L237.725 1514.29 L237.725 1536.81 L242.655 1536.81 L242.655 1540.7 L237.725 1540.7 L237.725 1548.85 L233.072 1548.85 L233.072 1540.7 L217.47 1540.7 L217.47 1536.19 L231.845 1514.29 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip500)\" d=\"M643.462 1532.02 L673.137 1532.02 L673.137 1535.95 L643.462 1535.95 L643.462 1532.02 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip500)\" d=\"M687.258 1544.91 L703.577 1544.91 L703.577 1548.85 L681.633 1548.85 L681.633 1544.91 Q684.295 1542.16 688.878 1537.53 Q693.484 1532.88 694.665 1531.53 Q696.91 1529.01 697.79 1527.27 Q698.693 1525.51 698.693 1523.82 Q698.693 1521.07 696.748 1519.33 Q694.827 1517.6 691.725 1517.6 Q689.526 1517.6 687.072 1518.36 Q684.642 1519.13 681.864 1520.68 L681.864 1515.95 Q684.688 1514.82 687.142 1514.24 Q689.596 1513.66 691.633 1513.66 Q697.003 1513.66 700.197 1516.35 Q703.392 1519.03 703.392 1523.52 Q703.392 1525.65 702.582 1527.57 Q701.795 1529.47 699.688 1532.07 Q699.109 1532.74 696.008 1535.95 Q692.906 1539.15 687.258 1544.91 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip500)\" d=\"M1135.48 1517.37 Q1131.87 1517.37 1130.04 1520.93 Q1128.24 1524.47 1128.24 1531.6 Q1128.24 1538.71 1130.04 1542.27 Q1131.87 1545.82 1135.48 1545.82 Q1139.12 1545.82 1140.92 1542.27 Q1142.75 1538.71 1142.75 1531.6 Q1142.75 1524.47 1140.92 1520.93 Q1139.12 1517.37 1135.48 1517.37 M1135.48 1513.66 Q1141.29 1513.66 1144.35 1518.27 Q1147.43 1522.85 1147.43 1531.6 Q1147.43 1540.33 1144.35 1544.94 Q1141.29 1549.52 1135.48 1549.52 Q1129.67 1549.52 1126.59 1544.94 Q1123.54 1540.33 1123.54 1531.6 Q1123.54 1522.85 1126.59 1518.27 Q1129.67 1513.66 1135.48 1513.66 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip500)\" d=\"M1592.1 1544.91 L1608.42 1544.91 L1608.42 1548.85 L1586.47 1548.85 L1586.47 1544.91 Q1589.14 1542.16 1593.72 1537.53 Q1598.33 1532.88 1599.51 1531.53 Q1601.75 1529.01 1602.63 1527.27 Q1603.53 1525.51 1603.53 1523.82 Q1603.53 1521.07 1601.59 1519.33 Q1599.67 1517.6 1596.57 1517.6 Q1594.37 1517.6 1591.91 1518.36 Q1589.48 1519.13 1586.71 1520.68 L1586.71 1515.95 Q1589.53 1514.82 1591.98 1514.24 Q1594.44 1513.66 1596.47 1513.66 Q1601.84 1513.66 1605.04 1516.35 Q1608.23 1519.03 1608.23 1523.52 Q1608.23 1525.65 1607.42 1527.57 Q1606.64 1529.47 1604.53 1532.07 Q1603.95 1532.74 1600.85 1535.95 Q1597.75 1539.15 1592.1 1544.91 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip500)\" d=\"M2062.42 1518.36 L2050.61 1536.81 L2062.42 1536.81 L2062.42 1518.36 M2061.19 1514.29 L2067.07 1514.29 L2067.07 1536.81 L2072 1536.81 L2072 1540.7 L2067.07 1540.7 L2067.07 1548.85 L2062.42 1548.85 L2062.42 1540.7 L2046.82 1540.7 L2046.82 1536.19 L2061.19 1514.29 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><polyline clip-path=\"url(#clip502)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"149.191,1479.62 2352.76,1479.62 \"/>\n",
       "<polyline clip-path=\"url(#clip502)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"149.191,1273.27 2352.76,1273.27 \"/>\n",
       "<polyline clip-path=\"url(#clip502)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"149.191,1066.93 2352.76,1066.93 \"/>\n",
       "<polyline clip-path=\"url(#clip502)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"149.191,860.58 2352.76,860.58 \"/>\n",
       "<polyline clip-path=\"url(#clip502)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"149.191,654.234 2352.76,654.234 \"/>\n",
       "<polyline clip-path=\"url(#clip502)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"149.191,447.887 2352.76,447.887 \"/>\n",
       "<polyline clip-path=\"url(#clip502)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"149.191,241.541 2352.76,241.541 \"/>\n",
       "<polyline clip-path=\"url(#clip500)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"149.191,1486.45 149.191,47.2441 \"/>\n",
       "<polyline clip-path=\"url(#clip500)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"149.191,1479.62 168.089,1479.62 \"/>\n",
       "<polyline clip-path=\"url(#clip500)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"149.191,1273.27 168.089,1273.27 \"/>\n",
       "<polyline clip-path=\"url(#clip500)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"149.191,1066.93 168.089,1066.93 \"/>\n",
       "<polyline clip-path=\"url(#clip500)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"149.191,860.58 168.089,860.58 \"/>\n",
       "<polyline clip-path=\"url(#clip500)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"149.191,654.234 168.089,654.234 \"/>\n",
       "<polyline clip-path=\"url(#clip500)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"149.191,447.887 168.089,447.887 \"/>\n",
       "<polyline clip-path=\"url(#clip500)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"149.191,241.541 168.089,241.541 \"/>\n",
       "<path clip-path=\"url(#clip500)\" d=\"M50.9921 1480.07 L80.6679 1480.07 L80.6679 1484.01 L50.9921 1484.01 L50.9921 1480.07 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip500)\" d=\"M103.608 1466.41 L91.8021 1484.86 L103.608 1484.86 L103.608 1466.41 M102.381 1462.34 L108.26 1462.34 L108.26 1484.86 L113.191 1484.86 L113.191 1488.75 L108.26 1488.75 L108.26 1496.9 L103.608 1496.9 L103.608 1488.75 L88.0058 1488.75 L88.0058 1484.24 L102.381 1462.34 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip500)\" d=\"M52.1264 1273.72 L81.8021 1273.72 L81.8021 1277.66 L52.1264 1277.66 L52.1264 1273.72 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip500)\" d=\"M106.061 1271.92 Q109.418 1272.64 111.293 1274.9 Q113.191 1277.17 113.191 1280.51 Q113.191 1285.62 109.672 1288.42 Q106.154 1291.22 99.6724 1291.22 Q97.4965 1291.22 95.1817 1290.78 Q92.89 1290.37 90.4364 1289.51 L90.4364 1285 Q92.3808 1286.13 94.6956 1286.71 Q97.0104 1287.29 99.5335 1287.29 Q103.932 1287.29 106.223 1285.55 Q108.538 1283.82 108.538 1280.51 Q108.538 1277.45 106.385 1275.74 Q104.256 1274 100.436 1274 L96.4085 1274 L96.4085 1270.16 L100.621 1270.16 Q104.071 1270.16 105.899 1268.79 Q107.728 1267.4 107.728 1264.81 Q107.728 1262.15 105.83 1260.74 Q103.955 1259.3 100.436 1259.3 Q98.515 1259.3 96.316 1259.72 Q94.1169 1260.14 91.478 1261.02 L91.478 1256.85 Q94.14 1256.11 96.4548 1255.74 Q98.7928 1255.37 100.853 1255.37 Q106.177 1255.37 109.279 1257.8 Q112.381 1260.21 112.381 1264.33 Q112.381 1267.2 110.737 1269.19 Q109.094 1271.15 106.061 1271.92 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip500)\" d=\"M53.0754 1067.38 L82.7512 1067.38 L82.7512 1071.31 L53.0754 1071.31 L53.0754 1067.38 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip500)\" d=\"M96.8715 1080.27 L113.191 1080.27 L113.191 1084.21 L91.2465 1084.21 L91.2465 1080.27 Q93.9086 1077.52 98.4919 1072.89 Q103.098 1068.23 104.279 1066.89 Q106.524 1064.37 107.404 1062.63 Q108.307 1060.87 108.307 1059.18 Q108.307 1056.43 106.362 1054.69 Q104.441 1052.96 101.339 1052.96 Q99.14 1052.96 96.6863 1053.72 Q94.2558 1054.48 91.478 1056.04 L91.478 1051.31 Q94.3021 1050.18 96.7558 1049.6 Q99.2095 1049.02 101.246 1049.02 Q106.617 1049.02 109.811 1051.71 Q113.006 1054.39 113.006 1058.88 Q113.006 1061.01 112.196 1062.93 Q111.408 1064.83 109.302 1067.42 Q108.723 1068.1 105.621 1071.31 Q102.52 1074.51 96.8715 1080.27 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip500)\" d=\"M52.7051 861.031 L82.3808 861.031 L82.3808 864.967 L52.7051 864.967 L52.7051 861.031 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip500)\" d=\"M93.2836 873.925 L100.922 873.925 L100.922 847.559 L92.6123 849.226 L92.6123 844.967 L100.876 843.3 L105.552 843.3 L105.552 873.925 L113.191 873.925 L113.191 877.86 L93.2836 877.86 L93.2836 873.925 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip500)\" d=\"M101.246 640.032 Q97.6354 640.032 95.8067 643.597 Q94.0012 647.139 94.0012 654.268 Q94.0012 661.375 95.8067 664.94 Q97.6354 668.481 101.246 668.481 Q104.881 668.481 106.686 664.94 Q108.515 661.375 108.515 654.268 Q108.515 647.139 106.686 643.597 Q104.881 640.032 101.246 640.032 M101.246 636.329 Q107.057 636.329 110.112 640.935 Q113.191 645.519 113.191 654.268 Q113.191 662.995 110.112 667.602 Q107.057 672.185 101.246 672.185 Q95.4363 672.185 92.3576 667.602 Q89.3021 662.995 89.3021 654.268 Q89.3021 645.519 92.3576 640.935 Q95.4363 636.329 101.246 636.329 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip500)\" d=\"M93.2836 461.232 L100.922 461.232 L100.922 434.867 L92.6123 436.533 L92.6123 432.274 L100.876 430.607 L105.552 430.607 L105.552 461.232 L113.191 461.232 L113.191 465.167 L93.2836 465.167 L93.2836 461.232 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip500)\" d=\"M96.8715 254.886 L113.191 254.886 L113.191 258.821 L91.2465 258.821 L91.2465 254.886 Q93.9086 252.131 98.4919 247.502 Q103.098 242.849 104.279 241.506 Q106.524 238.983 107.404 237.247 Q108.307 235.488 108.307 233.798 Q108.307 231.044 106.362 229.307 Q104.441 227.571 101.339 227.571 Q99.14 227.571 96.6863 228.335 Q94.2558 229.099 91.478 230.65 L91.478 225.928 Q94.3021 224.794 96.7558 224.215 Q99.2095 223.636 101.246 223.636 Q106.617 223.636 109.811 226.321 Q113.006 229.007 113.006 233.497 Q113.006 235.627 112.196 237.548 Q111.408 239.446 109.302 242.039 Q108.723 242.71 105.621 245.928 Q102.52 249.122 96.8715 254.886 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><polyline clip-path=\"url(#clip502)\" style=\"stroke:#009af9; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"211.556,537.755 232.554,468.377 253.553,403.848 274.551,344.616 295.549,291.058 316.548,243.481 337.546,202.115 358.544,167.115 379.543,138.565 400.541,116.473 421.539,100.776 442.538,91.3433 463.536,87.9763 484.534,90.4162 505.533,98.3467 526.531,111.399 547.529,129.157 568.528,151.166 589.526,176.934 610.524,205.944 631.523,237.656 652.521,271.516 673.519,306.965 694.518,343.441 715.516,380.392 736.514,417.276 757.513,453.572 778.511,488.787 799.509,522.456 820.508,554.153 841.506,583.494 862.504,610.139 883.503,633.798 904.501,654.234 925.499,671.264 946.498,684.761 967.496,694.656 988.494,700.938 1009.49,703.65 1030.49,702.895 1051.49,698.825 1072.49,691.648 1093.49,681.618 1114.48,669.033 1135.48,654.234 1156.48,637.594 1177.48,619.519 1198.48,600.439 1219.48,580.803 1240.47,561.073 1261.47,541.717 1282.47,523.205 1303.47,505.997 1324.47,490.545 1345.47,477.278 1366.46,466.604 1387.46,458.896 1408.46,454.494 1429.46,453.696 1450.46,456.753 1471.46,463.868 1492.45,475.188 1513.45,490.805 1534.45,510.752 1555.45,535.002 1576.45,563.466 1597.45,595.995 1618.44,632.376 1639.44,672.339 1660.44,715.556 1681.44,761.643 1702.44,810.165 1723.44,860.641 1744.43,912.543 1765.43,965.31 1786.43,1018.35 1807.43,1071.03 1828.43,1122.72 1849.43,1172.77 1870.42,1220.53 1891.42,1265.32 1912.42,1306.52 1933.42,1343.5 1954.42,1375.66 1975.42,1402.42 1996.41,1423.26 2017.41,1437.7 2038.41,1445.31 2059.41,1445.72 2080.41,1438.62 2101.41,1423.79 2122.4,1401.07 2143.4,1370.36 2164.4,1331.68 2185.4,1285.1 2206.4,1230.79 2227.4,1169 2248.39,1100.07 2269.39,1024.4 2290.39,942.516 \"/>\n",
       "<path clip-path=\"url(#clip500)\" d=\"M2006.52 198.898 L2279.3 198.898 L2279.3 95.2176 L2006.52 95.2176  Z\" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<polyline clip-path=\"url(#clip500)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"2006.52,198.898 2279.3,198.898 2279.3,95.2176 2006.52,95.2176 2006.52,198.898 \"/>\n",
       "<polyline clip-path=\"url(#clip500)\" style=\"stroke:#009af9; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"2031,147.058 2177.91,147.058 \"/>\n",
       "<path clip-path=\"url(#clip500)\" d=\"M2216.23 166.745 Q2214.43 171.375 2212.71 172.787 Q2211 174.199 2208.13 174.199 L2204.73 174.199 L2204.73 170.634 L2207.23 170.634 Q2208.99 170.634 2209.96 169.8 Q2210.93 168.967 2212.11 165.865 L2212.88 163.921 L2202.39 138.412 L2206.9 138.412 L2215.01 158.689 L2223.11 138.412 L2227.62 138.412 L2216.23 166.745 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip500)\" d=\"M2234.91 160.402 L2242.55 160.402 L2242.55 134.037 L2234.24 135.703 L2234.24 131.444 L2242.5 129.778 L2247.18 129.778 L2247.18 160.402 L2254.82 160.402 L2254.82 164.338 L2234.91 164.338 L2234.91 160.402 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /></svg>\n"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using Plots\n",
    "\n",
    "g(x) = x * sin(x + 1.0)\n",
    "\n",
    "plotgrid = range(-4, 5, length=100)\n",
    "plot(plotgrid, g.(plotgrid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "06694460-7f05-4853-ba42-0126cacf32da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Results of Optimization Algorithm\n",
       " * Algorithm: Brent's Method\n",
       " * Search Interval: [-4.000000, 5.000000]\n",
       " * Minimizer: -5.202690e-01\n",
       " * Minimum: -2.401252e-01\n",
       " * Iterations: 11\n",
       " * Convergence: max(|x - x_upper|, |x - x_lower|) <= 2*(1.5e-08*|x|+2.2e-16): true\n",
       " * Objective Function Calls: 12"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = optimize(g, -4.0, 5.0) # A syntax for univariate fns: optimize g between -4.0 and 5.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35573ae1-cf28-45ee-a2bf-c963e6ab9ce3",
   "metadata": {},
   "source": [
    "The package ```BlackBoxOptim.jl``` was conceived to perform global optimization in Julia. It uses meta-heuristics, such as [Differential Evolution](https://en.wikipedia.org/wiki/Differential_evolution). These typically involve initializing a number of candidates at different starting points, search for a minimum/maximum starting from those candidates and finally picking the candidate with the lowest/highest value reached. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d0743d80-cb2f-473a-b9ee-93525c914680",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting optimization with optimizer DiffEvoOpt{FitPopulation{Float64}, RadiusLimitedSelector, BlackBoxOptim.AdaptiveDiffEvoRandBin{3}, RandomBound{ContinuousRectSearchSpace}}\n",
      "0.00 secs, 0 evals, 0 steps\n",
      "\n",
      "Optimization stopped after 10001 steps and 0.03 seconds\n",
      "Termination reason: Max number of steps (10000) reached\n",
      "Steps per second = 286061.73\n",
      "Function evals per second = 288493.01\n",
      "Improvements/step = 0.29550\n",
      "Total function evaluations = 10086\n",
      "\n",
      "\n",
      "Best candidate found: [3.95976]\n",
      "\n",
      "Fitness: -3.839222897\n",
      "\n"
     ]
    }
   ],
   "source": [
    "using BlackBoxOptim\n",
    "\n",
    "g(x) = x[1] * sin(x[1] + 1.0)\n",
    "\n",
    "res = bboptimize(g, SearchRange = (-4.0, 5.0), NumDimensions = 1);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d6739a4-935d-49cb-bfb6-2be9d91fd1cf",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 4. JuMP \n",
    "[JuMP.jl](https://jump.dev/JuMP.jl/stable/) is an algebraic modeling language for mathematical optimization written in the Julia language. It supports a number of open-source and commercial solvers for a variety of problem classes, including linear, mixed-integer, second-order conic, semidefinite, and nonlinear programming.\n",
    "\n",
    "MIT Econ provides access through the research servers to two commercial solvers which may be of interest to you: **Knitro** (Nonlinear Interior point Trust Region Optimization), specialized in solving large-scale nonlinear optimization problems, and **Gurobi**, which solves linear, quadratic and mixed-integer programs (more on these in the next section). We won't have time to go into these two solvers in detail here, but I've added some links to the documentation at the end in case you want to learn more.\n",
    "\n",
    "According to the JuMP documentation, some reasons to use JuMP include:\n",
    "\n",
    "- User friendliness: JuMP has syntax that mimics natural mathematical expressions.\n",
    "\n",
    "- Access to advanced algorithmic techniques.\n",
    "\n",
    "- Solver independence: JuMP is just a generic, solver-independent modeling language, which makes it easier to change between a number of of open-source and commercial optimization software packages (\"solvers\").\n",
    "\n",
    "- Ease of embedding: JuMP is written purely in Julia, and provides automatic installation of many open-source solvers. This is different to modeling languages in Python which require you to download and install a solver yourself.\n",
    "\n",
    "- Speed.\n",
    "\n",
    "At the same time, there are some situations in which the use of JuMP is not recommended: \n",
    "\n",
    "- JuMP doesn't compose well with other Julia packages. If you want to optimize a complicated function that depends on other packages (e.g. a Neural Network from ```Flux.jl```), you should consider ```Optim.jl``` or other alternatives.\n",
    "\n",
    "- Derivative free or unconstrained optimization. The methods in JuMP require automatic differentiability of the objective function, so if your objective is not differentiable, you woud be better off using the Nelder-Mead option in ```Optim.jl``` or other alternatives. Similarly, even if your problem is differentiable, if it is unconstrained there is limited benefit to using JuMP over tools which are only concerned with function minimization.\n",
    "\n",
    "- Optimal control problems: there is a package, [InfiniteOpt.jl](https://github.com/infiniteopt/InfiniteOpt.jl), that builds on JuMP for infinite-dimensional optimization problems, such as stochastic or dynamic programming.\n",
    "\n",
    "We will see an example of how JuMP works in the context of the next section on Linear Programming."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6657fa7-24ac-4f11-b093-04fdb2b080a1",
   "metadata": {},
   "source": [
    "## 5. Linear and Quadratic Programming\n",
    "A **linear program** is a problem that can be expressed as:\n",
    "\\begin{align*}\n",
    "\\min_{x \\in \\mathbb{R}^n} \\quad & c' x \\\\\n",
    "\\text{subj. to} \\quad & Ax \\leq b \\\\\n",
    "& x \\geq 0.\n",
    "\\end{align*}\n",
    "\n",
    "Notice that, since the objective and the constraints are linear, looking for stationary points where the derivative of the objective is 0 will not work! \n",
    "\n",
    "An algorithm to solve this type of problems is the **simplex** algorithm. At each step, we look at one of the vertices of the feasible region, and we look for an adjacent vertex in which the value of the objective function is improved. If improvement is not possible, then we have found an optimal solution. The idea is simple in practice, but implementing it efficiently with many variables and constraints can be tricky! Luckily, there are packages in Julia that do this for us.\n",
    "\n",
    "![The simplex algorithm for LP](https://media.springernature.com/lw685/springer-static/image/chp%3A10.1007%2F978-1-4471-5283-5_3/MediaObjects/311704_1_En_3_Fig6_HTML.gif \"Simplex alg.\")\n",
    "\n",
    "Two related problems are:\n",
    "1. **Quadratic programming**: \n",
    "\\begin{align*}\n",
    "\\min_{x \\in \\mathbb{R}^n} \\quad & x'Qx + c'x \\\\\n",
    "\\text{subj. to} \\quad & Ax \\leq b\n",
    "\\end{align*} \n",
    "where the constraints are the same but now the objective is quadratic. This can be solved with the methods above (e.g. interior point methods), but there exist relatively efficient modifications of the simplex algorithm in this case too.\n",
    "\n",
    "2. **Integer programming**:\n",
    "\\begin{align*}\n",
    "\\min_{x \\in \\mathbb{Z}^n} \\quad & c' x \\\\\n",
    "\\text{subj. to} \\quad & Ax \\leq b \\\\\n",
    "& x \\geq 0.\n",
    "\\end{align*}\n",
    "with the additional restriction that the components of $x \\in \\mathbb{Z}^n$ are integer numbers. Mixed-integer problems are those in which some variables must be integers, but other variables may be continuous.\n",
    "\n",
    "Below we will use the ```JuMP.jl``` modeling language and the ```HiGHS.jl``` open-source solver to solve a linear program. ```HiGHS.jl``` is based on the high performance dual revised simplex implementation for large-scale linear, quadratic (and mixed-integer) programming.\n",
    "\n",
    "### 5.1. Example: the cannery problem\n",
    "Let's take this example from the JuMP documentation. We are trying to minimize the cost of shipping cans from production plants $p\\in P$ to markets $m \\in M$. Each production plant $p$ has capacity $c_p$, and each market $m$ has a demand $d_m$. The cost of shipping from plant $p$ to market $m$ is $\\tau_{pm}$. The problem is therefore:\n",
    "\\begin{align*}\n",
    "\\min_{x \\in \\mathbb{R}^n} \\quad & \\sum_{p\\in P} \\sum_{m \\in M} \\tau_{pm} x_{pm} \\\\\n",
    "\\text{subj. to} \\quad & \\sum_{m \\in M} x_{pm} \\leq c_p \\quad \\forall p \\in P \\\\\n",
    "& \\sum_{p \\in P} x_{pm} \\geq d_m  \\quad \\forall m \\in M \\\\\n",
    "& x_{pm} \\geq 0 \\quad \\forall p \\in P, \\quad \\forall m \\in M\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8c4fde5e-2692-46b8-90d0-62bd0a1fe772",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$$ \\begin{aligned}\n",
       "\\min\\quad & 1.7 x_{Seattle,Chicago} + 1.8 x_{Seattle,Topeka} + 2.5 x_{Seattle,New-York} + 1.8 x_{San-Diego,Chicago} + 1.4 x_{San-Diego,Topeka} + 2.5 x_{San-Diego,New-York}\\\\\n",
       "\\text{Subject to} \\quad & x_{Seattle,Chicago} + x_{San-Diego,Chicago} \\geq 300\\\\\n",
       " & x_{Seattle,Topeka} + x_{San-Diego,Topeka} \\geq 300\\\\\n",
       " & x_{Seattle,New-York} + x_{San-Diego,New-York} \\geq 300\\\\\n",
       " & x_{Seattle,Chicago} + x_{Seattle,Topeka} + x_{Seattle,New-York} \\leq 350\\\\\n",
       " & x_{San-Diego,Chicago} + x_{San-Diego,Topeka} + x_{San-Diego,New-York} \\leq 600\\\\\n",
       " & x_{Seattle,Chicago} \\geq 0\\\\\n",
       " & x_{San-Diego,Chicago} \\geq 0\\\\\n",
       " & x_{Seattle,Topeka} \\geq 0\\\\\n",
       " & x_{San-Diego,Topeka} \\geq 0\\\\\n",
       " & x_{Seattle,New-York} \\geq 0\\\\\n",
       " & x_{San-Diego,New-York} \\geq 0\\\\\n",
       "\\end{aligned} $$"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "using JuMP, HiGHS\n",
    "\n",
    "data = Dict(\"plants\" => Dict(\n",
    "        \"Seattle\" => Dict(\"capacity\" => 350),\n",
    "        \"San-Diego\" => Dict(\"capacity\" => 600)\n",
    "    ),\n",
    "    \"markets\" => Dict(\n",
    "        \"New-York\" => Dict(\"demand\" => 300),\n",
    "        \"Chicago\" => Dict(\"demand\" => 300),\n",
    "        \"Topeka\" => Dict(\"demand\" => 300)\n",
    "    ),\n",
    "    \"costs\" => Dict(\n",
    "        \"Seattle => New-York\" => 2.5,\n",
    "        \"Seattle => Chicago\" => 1.7,\n",
    "        \"Seattle => Topeka\" => 1.8,\n",
    "        \"San-Diego => New-York\" => 2.5,\n",
    "        \"San-Diego => Chicago\" => 1.8,\n",
    "        \"San-Diego => Topeka\" => 1.4\n",
    "        )\n",
    ")\n",
    "\n",
    "# Get set of plants and markets\n",
    "P = keys(data[\"plants\"])\n",
    "M = keys(data[\"markets\"])\n",
    "\n",
    "# Function to find costs:\n",
    "cost(p::String, m::String) = data[\"costs\"][\"$p => $m\"]\n",
    "\n",
    "# Define a JuMP model:\n",
    "model = Model(HiGHS.Optimizer)\n",
    "\n",
    "# Our decision variables are indexed over the set of plants and markets:\n",
    "@variable(model, x[P, M] >= 0)\n",
    "\n",
    "# We need a constraint that each plant can ship no more than its capacity:\n",
    "@constraint(model, [p in P], sum(x[p, :]) <= data[\"plants\"][p][\"capacity\"])\n",
    "\n",
    "# and each market must receive at least its demand:\n",
    "@constraint(model, [m in M], sum(x[:, m]) >= data[\"markets\"][m][\"demand\"])\n",
    "\n",
    "# Our objective is to minimize the transportation distance:\n",
    "@objective(model, Min, sum(cost(p, m) * x[p, m] for p in P, m in M))\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d4795a98-f874-4d38-b9bd-41877357156c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running HiGHS 1.6.0: Copyright (c) 2023 HiGHS under MIT licence terms\n",
      "Presolving model\n",
      "5 rows, 6 cols, 12 nonzeros\n",
      "5 rows, 6 cols, 12 nonzeros\n",
      "Presolve : Reductions: rows 5(-0); columns 6(-0); elements 12(-0) - Not reduced\n",
      "Problem not reduced by presolve: solving the LP\n",
      "Using EKK dual simplex solver - serial\n",
      "  Iteration        Objective     Infeasibilities num(sum)\n",
      "          0     0.0000000000e+00 Pr: 3(900) 0s\n",
      "          3     1.6800000000e+03 Pr: 0(0) 0s\n",
      "Model   status      : Optimal\n",
      "Simplex   iterations: 3\n",
      "Objective value     :  1.6800000000e+03\n",
      "HiGHS run time      :          0.00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "* Solver : HiGHS\n",
       "\n",
       "* Status\n",
       "  Result count       : 1\n",
       "  Termination status : OPTIMAL\n",
       "  Message from the solver:\n",
       "  \"kHighsModelStatusOptimal\"\n",
       "\n",
       "* Candidate solution (result #1)\n",
       "  Primal status      : FEASIBLE_POINT\n",
       "  Dual status        : FEASIBLE_POINT\n",
       "  Objective value    : 1.68000e+03\n",
       "  Objective bound    : 0.00000e+00\n",
       "  Relative gap       : Inf\n",
       "  Dual objective value : 1.68000e+03\n",
       "\n",
       "* Work counters\n",
       "  Solve time (sec)   : 1.87779e-03\n",
       "  Simplex iterations : 3\n",
       "  Barrier iterations : 0\n",
       "  Node count         : -1\n"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Solve\n",
    "optimize!(model)\n",
    "solution_summary(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b354f7ca-37a0-45a2-8b33-d1775f0ec385",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seattle => Chicago: 300.0\n",
      "Seattle => Topeka: 0.0\n",
      "Seattle => New-York: 0.0\n",
      "San-Diego => Chicago: 0.0\n",
      "San-Diego => Topeka: 300.0\n",
      "San-Diego => New-York: 300.0\n"
     ]
    }
   ],
   "source": [
    "# Optimal shipment:\n",
    "\n",
    "for p in P, m in M\n",
    "    println(p, \" => \", m, \": \", value(x[p, m]))\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da31192e-22f6-4be6-a101-8fedc5e2afa6",
   "metadata": {},
   "source": [
    "## 6. Stochastic Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de071bb-a332-4b99-be40-23109de513b3",
   "metadata": {},
   "source": [
    "### 6.1. Simulated Annealing \n",
    "\n",
    "**Simulated Annealing** is a probabilistic method for approximating  the global optimum of a function. The name of the algorithm comes from annealing in metallurgy, a technique involving heating and controlled cooling of a material to alter its physical properties. Simulated annealing can be used for very hard computational optimization problems where exact algorithms fail; even though it usually achieves an approximate solution to the global minimum, it could be enough for many practical problems. \n",
    "\n",
    "The method for sampling points is an adaptation of the Metropolis-Hastings algorithm. At each step $k = 0, \\ldots, k_{max}$, let $x_k$ denote the current candidate for the minimizer. Then:\n",
    "\n",
    "1. $x_k' = \\mathrm{neighbor}(x_k)$\n",
    "\n",
    "2. $T = \\mathrm{temperature}(k)$\n",
    "\n",
    "3. If $\\mathrm{P}(f(x_k), f(x_k'), T) \\geq u_k$, where $u_k \\sim U[0,1]$ then $x_{k+1} = x_k'$. Otherwise, $x_{k+1} = x_k$. \n",
    "    \n",
    "As you can see, to implement the algorithm, we need to specify three functions. The first one is $\\mathrm{neighbor}(x)$, which, for a given point, selects a random point closeby. One example would be $\\mathrm{neighbor}(x) = x + \\epsilon$ where $\\epsilon \\sim N(0, \\sigma^2 I)$. The second one is $T = \\mathrm{temperature}(k)$, a function of the current iteration that gives the annealing schedule. The third is the acceptance probability function $\\mathrm{P}(f(x), f(x'), T)$, which controls whether we accept the new state or not. In the original simulated annealing algorithm, this was $\\exp(-(f(x')-f(x))/T)$. The choices for these functions can have a significant impact on the method's effectiveness. Unfortunately, there are no choices of these parameters that will be good for all problems, and there is no general way to find the best choices for a given problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bfcdb8b7-4c1d-4833-a9ba-413717d44bdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " * Status: failure (reached maximum number of iterations)\n",
       "\n",
       " * Candidate solution\n",
       "    Final objective value:     8.928066e-03\n",
       "\n",
       " * Found with\n",
       "    Algorithm:     Simulated Annealing\n",
       "\n",
       " * Convergence measures\n",
       "    |x - x'|               = NaN ≰ 0.0e+00\n",
       "    |x - x'|/|x'|          = NaN ≰ 0.0e+00\n",
       "    |f(x) - f(x')|         = NaN ≰ 0.0e+00\n",
       "    |f(x) - f(x')|/|f(x')| = NaN ≰ 0.0e+00\n",
       "    |g(x)|                 = NaN ≰ 1.0e-08\n",
       "\n",
       " * Work counters\n",
       "    Seconds run:   0  (vs limit Inf)\n",
       "    Iterations:    1000\n",
       "    f(x) calls:    1001\n"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = optimize(f, [0.0, 0.0], SimulatedAnnealing())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a6182b06-7a74-4f93-ade2-18c403a1ff54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optim.converged(result) = false\n",
      "result.minimum = 0.008928065627760433\n",
      "result.minimizer = [1.0083046165851617, 1.007265921159627]\n"
     ]
    }
   ],
   "source": [
    "@show Optim.converged(result) \n",
    "@show result.minimum\n",
    "@show result.minimizer;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2183defa-0fb8-46f0-b328-4a7403c55f80",
   "metadata": {},
   "source": [
    "The method did not converge in 1,000 iterations. I checked for up to 100,000,000 and it still didn't converge with that many (although you can see it gets close!).\n",
    "\n",
    "Simulation-based methods will typically need many iterations to converge as a trade-off for their global convergence properties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8a72f309-e0db-40e5-b154-70811499b2f0",
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "Failed to converge in 1000 iterations",
     "output_type": "error",
     "traceback": [
      "Failed to converge in 1000 iterations",
      "",
      "Stacktrace:",
      " [1] error(s::String)",
      "   @ Base ./error.jl:35",
      " [2] top-level scope",
      "   @ In[16]:4"
     ]
    }
   ],
   "source": [
    "# Use this to throw an error when the method does not converge:\n",
    "# Syntax: BOOLEAN || if FALSE do this\n",
    "\n",
    "Optim.converged(result) || error(\"Failed to converge in $(Optim.iterations(result)) iterations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4045558-dded-4e78-9013-34d669299c17",
   "metadata": {},
   "source": [
    "### 6.2. Stochastic Gradient Methods\n",
    "In some cases, we may be interested in estimating a parameter that solves the following problem:\n",
    "$$\\theta_0 = \\arg\\min_{\\theta \\in \\Theta} L(\\theta) = \\arg\\min_{\\theta \\in \\Theta} E[\\ell(W, \\theta)].$$\n",
    "Some examples are OLS, LASSO, Ridge, or training a Neural Network. Under regularity conditions, the true parameter will satisfy the following FOC:\n",
    "$$E[\\nabla_{\\theta} \\ell(W, \\theta_0)] = 0.$$\n",
    "\n",
    "Suppose we have an i.i.d. sample $\\{W_i\\}_{i=1}^n$. We may estimate $\\theta_0$ by optimizing the sample analogue of the problem above:\n",
    "$$\\widehat{\\theta} = \\arg\\min_{\\theta \\in \\Theta} \\widehat{L}(\\theta) = \\frac{1}{n}\\sum_{i=1}^n \\ell(W_i, \\theta).$$\n",
    "Gradient-based numerical methods would typically solve this by finding a root of the FOC, e.g.:\n",
    "$$\\frac{1}{n}\\sum_{i=1}^n \\nabla_{\\theta} \\ell(W_i, \\widehat{\\theta}) = 0.,$$ for example, by gradient descent.\n",
    "\n",
    "However, when $n$ is very large, computing the average gradient over the whole sample may be computationally very costly. On the other hand, when the dimension of $\\theta$ is large, the minimizer of the sample loss may be quite far from the minimizer of the population loss. The larger the number of parameters, the more features of the data the model can capture, but those features may be noise rather than signal (_overfitting_). For these two reasons, people working with ML models tend to work with **stochastic gradient descent (SGD)** more than pure gradient descent. At each iteration, a mini-batch $B_t \\subset \\{1, \\ldots, n\\}$ is randomly selected from within the sample, and the iterations proceed as:\n",
    "$$\\widehat{\\theta}_{t+1} = \\widehat{\\theta}_{t} - \\alpha_t \\frac{1}{|B_t|}\\sum_{i \\in B_t} \\nabla_{\\theta} \\ell(W_i, \\widehat{\\theta}_t)$$\n",
    "\n",
    "Notice that, because the mini-batch is different at each iteration, there is no guarantee of convergence for this algorithm. Convergence is typically achieved by (a) letting the step size $\\alpha_t \\to 0$ as training goes on, (b) stopping the training process once an out-of-sample validation measure stabilizes (for example, the average loss on a test sample, which is not used in training)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0404f2ce-ba17-46d1-97fa-cbbc0a3dc738",
   "metadata": {},
   "source": [
    "## 7. Recap of Best Practices\n",
    "\n",
    "1. **Using pre-existing solvers:** As I mentioned above, in general you should try to avoid coding your own optimizer, and use the pre-existing implementations. People who probably have more experience with Julia than you have worked for very long on those! That being said, make sure that you understand the methods you're using, read the documentation for the packages and are aware of the advantages and disadvantages of a method or a solver.\n",
    "\n",
    "2. **Finding a global vs. a local optimum:** If you're not sure whether your problem is strictly convex you can find a possibly local optimum (say with ```Optim.jl```) and then try optimizing again with that point plus some random noise in different directions as a starting value. In general, even if you think your problem is convex, it is always a good idea to verify that the optimum does not depend on the starting value. \n",
    "\n",
    "3. **After optimizing:** Read the exit code to make sure that the optimizer achieved convergence. It is a good practice to write code to throw an error and stop automatically if convergence was not achieved. If your problem is twice differentiable, it could be a good idea to verify that the F.O.C. and S.O.C. are satisfied.\n",
    "\n",
    "4. **Test:** Whenever possible, it is a good idea to verify that the solvers are working properly with toy examples for which you can find the analytic solution easily. In other cases, e.g. if your optimization is part of an estimation problem, you can design a Monte-Carlo simulation, where you generate random draws of data from the model for known values of the parameters, and see if your estimation procedure can recover those parameters accurately."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b68df082-b90a-41ad-a94f-4097e8fa11e2",
   "metadata": {},
   "source": [
    "## Additional Resources\n",
    "- Quantitative Economics with Julia: [Solvers, Optimizers, and Automatic Differentiation](https://julia.quantecon.org/more_julia/optimization_solver_packages.html)\n",
    "\n",
    "- Fedor Iskhakov's Foundations of Computational Economics course: [More on Newton-Raphson method](https://github.com/fediskhakov/CompEcon/blob/main/23_mutivariate_newton.ipynb)\n",
    "\n",
    "- Judd (1998) Chapter 4 and references therein.\n",
    "\n",
    "- [Introduction to Optimization with Genetic Algorithm](https://towardsdatascience.com/introduction-to-optimization-with-genetic-algorithm-2f5001d9964b) A primer on Evolutionary Algorithms (EA) and the Genetic Algorithm (GA). These are two stochastic optimization methods that are very popular among the ML community. \n",
    "\n",
    "- [Knitro](https://www.artelys.com/solvers/knitro/) and its Julia implementation [Knitro.jl](https://www.artelys.com/docs/knitro/3_referenceManual/knitroJuliareference.html)\n",
    "\n",
    "- [Gurobi](https://www.gurobi.com/solutions/gurobi-optimizer/) and its Julia implementation [Gurobi.jl](https://docs.juliahub.com/Gurobi/do9v6/0.7.7/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a79da31a-f91c-4ecf-9528-0c91afb78107",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.10.0",
   "language": "julia",
   "name": "julia-1.10"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
